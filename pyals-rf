#!/usr/bin/python3 
"""
Copyright 2021-2022 Salvatore Barone <salvatore.barone@unina.it>

This is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 3 of the License, or any later version.

This is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
more details.

You should have received a copy of the GNU General Public License along with
RMEncoder; if not, write to the Free Software Foundation, Inc., 51 Franklin
Street, Fifth Floor, Boston, MA 02110-1301, USA.
"""
import click, git, os, sys
from src.Classifier import Classifier
from src.ps_flow import ps_flow
from src.als_flow import als_one_step, als_two_steps
from src.als_wc_flow import als_wc_one_step, als_wc_two_steps
from src.combined_flow import full_one_step, full_two_steps
from src.DtGenConfigParser import *
from src.dtgen import dtgen

def git_updater():
    try:
        dir_path = os.path.dirname(os.path.realpath(__file__))
        repo = git.Repo(dir_path)
        repo.remotes.origin.fetch()
        local_head = repo.heads[0].commit
        remote_head = repo.remotes.origin.refs[0].commit
        if remote_head != local_head:
            print("Updating the tool...")
            repo.remotes.origin.pull()
            for submodule in repo.submodules:
                submodule.update(init = True, recursive = True)
            return True
        return False
    except git.exc.GitCommandError as e:
        print(e)
        print("\n*** Ensure you have access to the internet! ***\n")
        return False

@click.group()
def cli():
    pass


@click.command("dump")
@click.argument('pmmlfile', type=click.Path(exists=True, dir_okay=False))
def dump(pmmlfile):
    """
    Dump the classifier and exit
    
    PMMLFILE is the PMML file describing the model
    """
    classifier = Classifier(None)
    classifier.parse(pmmlfile)
    classifier.dump()


@click.command("ps")
@click.argument('configfile', type=click.Path(exists=True, dir_okay=False))
def bitwidth(configfile):
    """
    Performs precision-scaling approximation
    
    CONFIGFILE is the path of the JSON configuration file containing all parameters which are needed to the tool.
    """
    ps_flow(configfile)
    


@click.command("als")
@click.argument('approach', type = click.Choice(["whole", "divided"]))
@click.argument('configfile', type=click.Path(exists=True, dir_okay=False))
def als(approach, configfile):
    """
    Performs ALS approximation
    
    CONFIGFILE is the path of the JSON configuration file containing all parameters which are needed to the tool.
    """
    if approach == "whole":
        als_one_step(configfile)
    elif approach == "divided":
        als_two_steps(configfile)
        

@click.command("als-wc")
@click.argument('approach', type = click.Choice(["whole", "divided"]))
@click.argument('configfile', type=click.Path(exists=True, dir_okay=False))
def als_wc(approach, configfile):
    """
    Performs ALS approximation
    
    CONFIGFILE is the path of the JSON configuration file containing all parameters which are needed to the tool.
    """
    if approach == "whole":
        als_wc_one_step(configfile)
    elif approach == "divided":
        als_wc_two_steps(configfile)
        


@click.command("full")
@click.argument('approach', type = click.Choice(["whole", "divided"]))
@click.argument('configfile', type=click.Path(exists=True, dir_okay=False))
def full(approach, configfile):
    """
    Performs full approximation (both ps and als)
    
    CONFIGFILE is the path of the JSON configuration file containing all parameters which are needed to the tool.
    """
    if approach == "whole":
        full_one_step(configfile)
    elif approach == "divided":
        full_two_steps(configfile)


@click.command("learn")
@click.argument('clf', type = click.Choice(["dt", "rf", "bag", "wc"]), default = "rf")
@click.argument('dataset', type=click.Path(exists=True, dir_okay=False))
@click.argument('outputdir', type=click.Path(dir_okay=True), default = "output")
@click.option("-c", "--separator", type=str, default = ",", help="Separator character in the dataset file")
@click.option("-o", "--outcome", type = int, default = None, help = "Index of the column for the expected outcome. If it is the last column, you can skip specifying it.")
@click.option("-s", "--skip_header", is_flag = True, help = "Whether or not to skip the header in DATASET")
@click.option("-f", "--fraction", type = float, default = 0.9, help = "Fraction of data to be used as learning set. The remaining will be used as test data.")
@click.option("-d", "--depth", type = int, default = None, help = "Maximum depth of the tree(s)")
@click.option("-n", "--predictors", type = int, default = 1, help = "The number of trees in the ensemble. Ignored if clf is dt.")
@click.option("--criterion", type = click.Choice(["gini", "entropy", "log_loss"]), default = "gini", help = "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain")
@click.option("--min_sample_split", type = int, default = 2, help = "The minimum number of samples required to split an internal node.")
@click.option("--min_samples_leaf", type = int, default = 1, help = "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches.")
@click.option("--max_features", default = None, help = "The number of features to consider when looking for the best split. You can also specify one between \"sqrt\", \"log2\" or \"auto\"")
@click.option("--max_leaf_nodes", type = int, default = None, help = "Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.")
@click.option("--min_impurity_decrease", type = float, default = 0.0, help = "A node will be split if this split induces a decrease of the impurity greater than or equal to this value.")
@click.option("--ccp_alpha", type = float, default = 0.0, help = "Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed.")
@click.option("-b", "--disable_bootstrap", is_flag = True, help = "Disable the bootstrap")
def learning(clf, dataset, outputdir, separator, outcome, skip_header, fraction, depth, predictors, criterion, min_sample_split, min_samples_leaf, max_features, max_leaf_nodes, min_impurity_decrease, ccp_alpha, disable_bootstrap):
    """
    Generates a decision tree/ random forest / bagging from CSV data.

    CLF is the classifier type: "dt" stands for decision tree, "rf" for random forest, "bag" for bagging.

    DATASET is the csv file to be used as a learning set.
    """
    dtgen(clf, dataset, outputdir, separator, outcome, skip_header, fraction, depth, predictors, criterion, min_sample_split, min_samples_leaf, max_features, max_leaf_nodes, min_impurity_decrease, ccp_alpha, disable_bootstrap)


cli.add_command(dump)
cli.add_command(bitwidth)
cli.add_command(als)
cli.add_command(als_wc)
cli.add_command(full)
cli.add_command(learning)

if __name__ == '__main__':
	if git_updater():
		os.execv(sys.argv[0], sys.argv)
	else:
		cli()

